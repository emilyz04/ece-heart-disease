{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential, clone_model\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, LeakyReLU\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dataset loading\n",
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ptyEkdFBAjsD",
        "outputId": "4c890214-bf8b-4358-84fb-7c45ec795713"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "heart_disease = fetch_ucirepo(id=45)\n",
        "X_df = heart_disease.data.features.dropna()\n",
        "y_df = heart_disease.data.targets.loc[X_df.index]\n",
        "y_df = (y_df > 0).astype(int)\n",
        "X_arr = X_df.values.astype(np.float32)\n",
        "y_arr = y_df.values.ravel().astype(np.int32)"
      ],
      "metadata": {
        "id": "5DqnKbLeqOkv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Baseline DNN Function\n",
        "def build_model(input_dim, hidden_units):\n",
        "    inputs = Input(shape=(input_dim,))\n",
        "    x = Dense(hidden_units)(inputs)\n",
        "    x = LeakyReLU(negative_slope=0.01)(x)\n",
        "    x = Dense(round(hidden_units / 2))(x)\n",
        "    x = LeakyReLU(negative_slope=0.01)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "EYtAKvABqHqX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline DNN\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=0)\n",
        "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "accs, precs, recs, f1s = [], [], [], []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X_arr, y_arr), 1):\n",
        "    print(f\"\\n--- Fold {fold} ---\")\n",
        "\n",
        "    X_tr, X_te = X_arr[train_idx], X_arr[test_idx]\n",
        "    y_tr, y_te = y_arr[train_idx], y_arr[test_idx]\n",
        "\n",
        "    # Standard scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_tr_scaled = scaler.fit_transform(X_tr)\n",
        "    X_te_scaled = scaler.transform(X_te)\n",
        "\n",
        "    # PCA\n",
        "    pca = PCA(n_components=0.95)\n",
        "    X_tr_pca = pca.fit_transform(X_tr_scaled)\n",
        "    X_te_pca = pca.transform(X_te_scaled)\n",
        "\n",
        "    # Class weights\n",
        "    cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
        "    cw_dict = dict(enumerate(cw))\n",
        "\n",
        "    # Model build + train\n",
        "    model = build_model(input_dim=X_tr_pca.shape[1], hidden_units=200)\n",
        "    model.fit(\n",
        "        X_tr_pca, y_tr,\n",
        "        validation_data=(X_te_pca, y_te),\n",
        "        epochs=1500,\n",
        "        batch_size=32,\n",
        "        class_weight=cw_dict,\n",
        "        callbacks=[reduce_lr, es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluation\n",
        "    y_pred = (model.predict(X_te_pca, verbose=0) > 0.5).astype(int).ravel()\n",
        "    acc = accuracy_score(y_te, y_pred)\n",
        "    prec = precision_score(y_te, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_te, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_te, y_pred, zero_division=0)\n",
        "    print(f\"Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "    accs.append(acc)\n",
        "    precs.append(prec)\n",
        "    recs.append(rec)\n",
        "    f1s.append(f1)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n--- 3-Fold CV Summary ---\")\n",
        "print(f\"Accuracy : {np.mean(accs):.3f}\")\n",
        "print(f\"Precision: {np.mean(precs):.3f}\")\n",
        "print(f\"Recall   : {np.mean(recs):.3f}\")\n",
        "print(f\"F1 Score : {np.mean(f1s):.3f}\")"
      ],
      "metadata": {
        "id": "BDD9FdZEZvqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f26ecc-d422-480c-de27-bac6b7485a38"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1 ---\n",
            "Accuracy: 0.859, Precision: 0.830, Recall: 0.867, F1: 0.848\n",
            "\n",
            "--- Fold 2 ---\n",
            "Accuracy: 0.788, Precision: 0.805, Recall: 0.717, F1: 0.759\n",
            "\n",
            "--- Fold 3 ---\n",
            "Accuracy: 0.838, Precision: 0.875, Recall: 0.761, F1: 0.814\n",
            "\n",
            "--- 3-Fold CV Summary ---\n",
            "Accuracy : 0.828\n",
            "Precision: 0.837\n",
            "Recall   : 0.782\n",
            "F1 Score : 0.807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define SCANN Functions\n",
        "\n",
        "def apply_masks_to_model(model, masks):\n",
        "    mask_idx = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            w, b = layer.get_weights()\n",
        "            mask = masks[mask_idx]\n",
        "            if w.shape != mask.shape:\n",
        "                raise ValueError(f\"Shape mismatch: weight {w.shape} vs mask {mask.shape}\")\n",
        "            w = w * mask.numpy()  # still safe and simple for clarity, avoids graph tracing\n",
        "            layer.set_weights([w, b])\n",
        "            mask_idx += 1\n",
        "\n",
        "def initialize_masks(model):\n",
        "    masks = []\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Dense):\n",
        "            shape = layer.kernel.shape\n",
        "            mask = tf.Variable(tf.ones(shape, dtype=tf.float32), trainable=False)\n",
        "            masks.append(mask)\n",
        "    return masks\n",
        "\n",
        "def grow_connections(model, masks, growth_frac, Xb, yb):\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "    with tf.GradientTape() as tape:\n",
        "        preds = model(Xb, training=True)\n",
        "        loss = loss_fn(yb, preds)\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "\n",
        "    for idx in range(0, len(model.trainable_weights), 2):  # skip biases\n",
        "        w = model.trainable_weights[idx]\n",
        "        gw = grads[idx]\n",
        "\n",
        "        W_np = w.numpy()\n",
        "        G_np = gw.numpy()\n",
        "        C_np = masks[idx // 2].numpy()\n",
        "\n",
        "        dormant = (C_np == 0)\n",
        "        grad_magnitude = np.abs(G_np) * dormant\n",
        "        num_to_grow = int(np.ceil(growth_frac * np.sum(dormant)))\n",
        "\n",
        "        if num_to_grow == 0:\n",
        "            continue\n",
        "\n",
        "        flat_idx = np.argpartition(grad_magnitude.flatten(), -num_to_grow)[-num_to_grow:]\n",
        "        row_idx, col_idx = np.unravel_index(flat_idx, grad_magnitude.shape)\n",
        "\n",
        "        for r, c in zip(row_idx, col_idx):\n",
        "            W_np[r, c] = np.random.normal(scale=0.01)\n",
        "            C_np[r, c] = 1\n",
        "\n",
        "        w.assign(W_np)\n",
        "        masks[idx // 2].assign(C_np)\n",
        "\n",
        "def prune_connections(model, masks, prune_frac, Xb, yb):\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        preds = model(Xb, training=True)\n",
        "        loss = loss_fn(yb, preds)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "\n",
        "    for idx in range(0, len(model.trainable_weights), 2):  # skip biases\n",
        "        w_tensor = model.trainable_weights[idx]\n",
        "        g_tensor = grads[idx]\n",
        "\n",
        "        W = w_tensor.numpy()\n",
        "        G = g_tensor.numpy()\n",
        "        mask = masks[idx // 2].numpy()\n",
        "\n",
        "        grad_magnitude = np.abs(G)\n",
        "        num_to_prune = int(np.ceil(prune_frac * grad_magnitude.size))\n",
        "        if num_to_prune == 0:\n",
        "            continue\n",
        "\n",
        "        threshold = np.partition(grad_magnitude.flatten(), num_to_prune)[num_to_prune]\n",
        "        prune_mask = grad_magnitude <= threshold\n",
        "\n",
        "        W[prune_mask] = 0\n",
        "        mask[prune_mask] = 0\n",
        "\n",
        "        w_tensor.assign(W)\n",
        "        masks[idx // 2].assign(mask)\n",
        "\n",
        "def grow_model(model, masks, new_units, noise_scale=0.1):\n",
        "    input_dim = model.input_shape[-1]\n",
        "    dense_layers = [layer for layer in model.layers if isinstance(layer, Dense)]\n",
        "\n",
        "    first_dense = dense_layers[0]\n",
        "    penultimate_dense = dense_layers[-2]\n",
        "    output_dense = dense_layers[-1]\n",
        "\n",
        "    w0, b0 = first_dense.get_weights()\n",
        "    wp, bp = penultimate_dense.get_weights()\n",
        "    w1, b1 = output_dense.get_weights()\n",
        "\n",
        "    old_units = w0.shape[1]\n",
        "    total_units = old_units + new_units\n",
        "\n",
        "    new_model = build_model(input_dim, total_units)\n",
        "    new_dense_layers = [layer for layer in new_model.layers if isinstance(layer, Dense)]\n",
        "    new_first_dense = new_dense_layers[0]\n",
        "    new_penultimate_dense = new_dense_layers[-2]\n",
        "    new_output_dense = new_dense_layers[-1]\n",
        "\n",
        "    # First Dense Layer (input to hidden)\n",
        "    W = np.random.normal(scale=noise_scale, size=(input_dim, total_units))\n",
        "    B = np.random.normal(scale=noise_scale, size=(total_units,))\n",
        "    W[:, :old_units] = w0\n",
        "    B[:old_units] = b0\n",
        "    new_first_dense.set_weights([W, B])\n",
        "\n",
        "    # Penultimate Dense Layer (hidden to mid)\n",
        "    hidden_mid_units = round(total_units / 2)\n",
        "    Wp = np.random.normal(scale=noise_scale, size=(total_units, hidden_mid_units))\n",
        "    Bp = np.random.normal(scale=noise_scale, size=(hidden_mid_units,))\n",
        "    Wp[:wp.shape[0], :wp.shape[1]] = wp\n",
        "    Bp[:bp.shape[0]] = bp\n",
        "    new_penultimate_dense.set_weights([Wp, Bp])\n",
        "\n",
        "    # Output layer\n",
        "    if w1.ndim == 1:\n",
        "        w1 = w1[:, np.newaxis]\n",
        "    output_units = w1.shape[1]\n",
        "    W1 = np.random.normal(scale=noise_scale, size=(hidden_mid_units, output_units))\n",
        "    W1[:w1.shape[0], :w1.shape[1]] = w1\n",
        "    new_output_dense.set_weights([W1, b1])\n",
        "\n",
        "    # Update masks using tf.Variable to allow assignment later\n",
        "    new_masks = []\n",
        "\n",
        "    # First layer mask\n",
        "    old_mask0 = masks[0].numpy()\n",
        "    new_mask0 = np.zeros((input_dim, total_units), dtype=np.float32)\n",
        "    new_mask0[:, :old_units] = old_mask0\n",
        "    new_masks.append(tf.Variable(new_mask0, trainable=False))\n",
        "\n",
        "    # Penultimate layer mask\n",
        "    old_maskp = masks[1].numpy()\n",
        "    new_maskp = np.zeros((total_units, hidden_mid_units), dtype=np.float32)\n",
        "    new_maskp[:wp.shape[0], :wp.shape[1]] = old_maskp\n",
        "    new_masks.append(tf.Variable(new_maskp, trainable=False))\n",
        "\n",
        "    # Output layer mask\n",
        "    old_mask1 = masks[2].numpy()\n",
        "    new_mask1 = np.zeros((hidden_mid_units, output_units), dtype=np.float32)\n",
        "    new_mask1[:w1.shape[0], :w1.shape[1]] = old_mask1\n",
        "    new_masks.append(tf.Variable(new_mask1, trainable=False))\n",
        "\n",
        "    return new_model, new_masks"
      ],
      "metadata": {
        "id": "oBPpMeDmOoHH"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SCANN Scheme A\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0)\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Cross-validation\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "a_accs, a_precs, a_recs, a_f1s = [], [], [], []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X_arr, y_arr), start=1):\n",
        "          print(f\"\\n--- SCANN Scheme A Fold {fold} ---\")\n",
        "          x_train, X_te = X_arr[train_idx], X_arr[test_idx]\n",
        "          y_tr, y_te = y_arr[train_idx], y_arr[test_idx]\n",
        "\n",
        "          scaler = StandardScaler().fit(x_train)\n",
        "          x_train_scaled = scaler.transform(x_train)\n",
        "          X_te_scaled = scaler.transform(X_te)\n",
        "          pca = PCA(n_components=0.95).fit(x_train_scaled)\n",
        "          x_train_pca = pca.transform(x_train_scaled)\n",
        "          X_te_pca = pca.transform(X_te_scaled)\n",
        "\n",
        "          Xb = tf.convert_to_tensor(x_train_pca[:256], dtype=tf.float32)\n",
        "          yb = tf.convert_to_tensor(y_tr[:256], dtype=tf.float32)\n",
        "\n",
        "          cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
        "          cw_dict = dict(enumerate(cw))\n",
        "\n",
        "          model = build_model(input_dim=x_train_pca.shape[1], hidden_units=100)\n",
        "          masks = initialize_masks(model)\n",
        "          apply_masks_to_model(model, masks)\n",
        "\n",
        "          model.fit(x_train_pca, y_tr, validation_data=(X_te_pca, y_te),\n",
        "          epochs=100, batch_size=32, class_weight=cw_dict,\n",
        "          callbacks=[reduce_lr, es], verbose=0)\n",
        "\n",
        "          best_model = clone_model(model)\n",
        "          best_model.set_weights(model.get_weights())\n",
        "          best_val = model.evaluate(X_te_pca, y_te, verbose=0)[1]\n",
        "\n",
        "          for cycle in range(10):\n",
        "\n",
        "              print(f\"-- Cycle {cycle+1} --\")\n",
        "              grow_connections(model, masks, growth_frac=0.8, Xb=Xb, yb=yb)\n",
        "              apply_masks_to_model(model, masks)\n",
        "              model.fit(x_train_pca, y_tr, validation_data=(X_te_pca, y_te),\n",
        "              epochs=20, batch_size=32, class_weight=cw_dict,\n",
        "              callbacks=[reduce_lr, es], verbose=0)\n",
        "\n",
        "              model, masks = grow_model(model, masks, new_units=8)\n",
        "              apply_masks_to_model(model, masks)\n",
        "              model.fit(x_train_pca, y_tr, validation_data=(X_te_pca, y_te),\n",
        "              epochs=20, batch_size=32, class_weight=cw_dict,\n",
        "              callbacks=[reduce_lr, es], verbose=0)\n",
        "\n",
        "              prune_connections(model, masks, prune_frac=0.3, Xb=Xb, yb=yb)\n",
        "              apply_masks_to_model(model, masks)\n",
        "              model.fit(x_train_pca, y_tr, validation_data=(X_te_pca, y_te),\n",
        "              epochs=20, batch_size=32, class_weight=cw_dict,\n",
        "              callbacks=[reduce_lr, es], verbose=0)\n",
        "\n",
        "              val_acc = model.evaluate(X_te_pca, y_te, verbose=0)[1]\n",
        "              if val_acc > best_val:\n",
        "                  best_val = val_acc\n",
        "                  best_model = clone_model(model)\n",
        "                  best_model.set_weights(model.get_weights())\n",
        "\n",
        "          y_pred = (best_model.predict(X_te_pca, verbose=0) > 0.5).astype(int).ravel()\n",
        "          a = accuracy_score(y_te, y_pred)\n",
        "          p = precision_score(y_te, y_pred, zero_division=0)\n",
        "          r = recall_score(y_te, y_pred, zero_division=0)\n",
        "          f1 = f1_score(y_te, y_pred, zero_division=0)\n",
        "          print(f\"Accuracy: {a:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "          a_accs.append(a); a_precs.append(p); a_recs.append(r); a_f1s.append(f1)\n",
        "\n",
        "print(\"\\n--- SCANN Scheme A Cross-Validation Summary ---\")\n",
        "print(f\"Accuracy : {np.mean(a_accs):.3f}\")\n",
        "print(f\"Precision: {np.mean(a_precs):.3f}\")\n",
        "print(f\"Recall   : {np.mean(a_recs):.3f}\")\n",
        "print(f\"F1 Score : {np.mean(a_f1s):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b6IWQjfUK-5X",
        "outputId": "7fc9be07-ff9e-43a1-9690-2fb6b7c0fce2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SCANN Scheme A Fold 1 ---\n",
            "-- Cycle 1 --\n",
            "-- Cycle 2 --\n",
            "-- Cycle 3 --\n",
            "-- Cycle 4 --\n",
            "-- Cycle 5 --\n",
            "-- Cycle 6 --\n",
            "-- Cycle 7 --\n",
            "-- Cycle 8 --\n",
            "-- Cycle 9 --\n",
            "-- Cycle 10 --\n",
            "Accuracy: 0.869, Precision: 0.864, Recall: 0.844, F1: 0.854\n",
            "\n",
            "--- SCANN Scheme A Fold 2 ---\n",
            "-- Cycle 1 --\n",
            "-- Cycle 2 --\n",
            "-- Cycle 3 --\n",
            "-- Cycle 4 --\n",
            "-- Cycle 5 --\n",
            "-- Cycle 6 --\n",
            "-- Cycle 7 --\n",
            "-- Cycle 8 --\n",
            "-- Cycle 9 --\n",
            "-- Cycle 10 --\n",
            "Accuracy: 0.818, Precision: 0.833, Recall: 0.761, F1: 0.795\n",
            "\n",
            "--- SCANN Scheme A Fold 3 ---\n",
            "-- Cycle 1 --\n",
            "-- Cycle 2 --\n",
            "-- Cycle 3 --\n",
            "-- Cycle 4 --\n",
            "-- Cycle 5 --\n",
            "-- Cycle 6 --\n",
            "-- Cycle 7 --\n",
            "-- Cycle 8 --\n",
            "-- Cycle 9 --\n",
            "-- Cycle 10 --\n",
            "Accuracy: 0.838, Precision: 0.857, Recall: 0.783, F1: 0.818\n",
            "\n",
            "--- SCANN Scheme A Cross-Validation Summary ---\n",
            "Accuracy : 0.842\n",
            "Precision: 0.851\n",
            "Recall   : 0.796\n",
            "F1 Score : 0.823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SCANN Scheme B\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0)\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "b_accs, b_precs, b_recs, b_f1s = [], [], [], []\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X_arr, y_arr), 1):\n",
        "    print(f\"\\n--- SCANN Scheme B Fold {fold} ---\")\n",
        "\n",
        "    x_train, X_te = X_arr[train_idx], X_arr[test_idx]\n",
        "    y_tr, y_te = y_arr[train_idx], y_arr[test_idx]\n",
        "\n",
        "    scaler = StandardScaler().fit(x_train)\n",
        "    x_train_s = scaler.transform(x_train)\n",
        "    X_te_s = scaler.transform(X_te)\n",
        "    pca = PCA(0.95).fit(x_train_s)\n",
        "    x_train_pca = pca.transform(x_train_s)\n",
        "    X_te_pca = pca.transform(X_te_s)\n",
        "\n",
        "    Xb = tf.convert_to_tensor(x_train_pca[:256], dtype=tf.float32)\n",
        "    yb = tf.convert_to_tensor(y_tr[:256], dtype=tf.float32)\n",
        "\n",
        "    cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
        "    cw_dict = dict(enumerate(cw))\n",
        "\n",
        "    model = build_model(input_dim=x_train_pca.shape[1], hidden_units=300)\n",
        "    masks = initialize_masks(model)\n",
        "    apply_masks_to_model(model, masks)\n",
        "    model.fit(x_train_pca, y_tr, validation_data=(X_te_pca, y_te),\n",
        "              epochs=100, batch_size=32, class_weight=cw_dict,\n",
        "              callbacks=[reduce_lr, es], verbose=0)\n",
        "\n",
        "    best_model = clone_model(model)\n",
        "    best_model.set_weights(model.get_weights())\n",
        "    best_acc = model.evaluate(x_train_pca, y_tr, verbose=0)[1]\n",
        "\n",
        "    for cycle in range(10):\n",
        "        print(f\"-- Cycle {cycle + 1} --\")\n",
        "\n",
        "        # Connection pruning\n",
        "        prune_connections(model, masks, prune_frac=0.95, Xb=Xb, yb=yb)\n",
        "        apply_masks_to_model(model, masks)\n",
        "\n",
        "        # Fine-tune\n",
        "        model.fit(x_train_pca, y_tr, validation_split=0.2,\n",
        "                  epochs=20, batch_size=32, class_weight=cw_dict,\n",
        "                  callbacks=reduce_lr, verbose=0)\n",
        "\n",
        "        # Connection growth\n",
        "        grow_connections(model, masks, growth_frac=0.9, Xb=Xb, yb=yb)\n",
        "        apply_masks_to_model(model, masks)\n",
        "\n",
        "        # Fine-tune\n",
        "        model.fit(x_train_pca, y_tr, validation_split=0.2,\n",
        "                  epochs=20, batch_size=32, class_weight=cw_dict,\n",
        "                  callbacks=reduce_lr, verbose=0)\n",
        "\n",
        "        acc = model.evaluate(x_train_pca, y_tr, verbose=0)[1]\n",
        "        if acc > best_acc:\n",
        "            best_model = clone_model(model)\n",
        "            best_model.set_weights(model.get_weights())\n",
        "            best_acc = acc\n",
        "\n",
        "    y_pred = (best_model.predict(X_te_pca, verbose=0) > 0.5).astype(int).ravel()\n",
        "    a = accuracy_score(y_te, y_pred)\n",
        "    p = precision_score(y_te, y_pred, zero_division=0)\n",
        "    r = recall_score(y_te, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_te, y_pred, zero_division=0)\n",
        "    print(f\"Accuracy: {a:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "    b_accs.append(a); b_precs.append(p); b_recs.append(r); b_f1s.append(f1)\n",
        "\n",
        "print(\"\\n--- SCANN Scheme B Cross-Validation Summary ---\")\n",
        "print(f\"Accuracy : {np.mean(b_accs):.3f}\")\n",
        "print(f\"Precision: {np.mean(b_precs):.3f}\")\n",
        "print(f\"Recall   : {np.mean(b_recs):.3f}\")\n",
        "print(f\"F1 Score : {np.mean(b_f1s):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "m4pCo4h4DOsl",
        "outputId": "ff752784-b49d-44ef-aa7c-1c311d4edefe"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- SCANN Scheme B Fold 1 ---\n",
            "-- Cycle 1 --\n",
            "-- Cycle 2 --\n",
            "-- Cycle 3 --\n",
            "-- Cycle 4 --\n",
            "-- Cycle 5 --\n",
            "-- Cycle 6 --\n",
            "-- Cycle 7 --\n",
            "-- Cycle 8 --\n",
            "-- Cycle 9 --\n",
            "-- Cycle 10 --\n",
            "Accuracy: 0.879, Precision: 0.867, Recall: 0.867, F1: 0.867\n",
            "\n",
            "--- SCANN Scheme B Fold 2 ---\n",
            "-- Cycle 1 --\n",
            "-- Cycle 2 --\n",
            "-- Cycle 3 --\n",
            "-- Cycle 4 --\n",
            "-- Cycle 5 --\n",
            "-- Cycle 6 --\n",
            "-- Cycle 7 --\n",
            "-- Cycle 8 --\n",
            "-- Cycle 9 --\n",
            "-- Cycle 10 --\n",
            "Accuracy: 0.768, Precision: 0.795, Recall: 0.674, F1: 0.729\n",
            "\n",
            "--- SCANN Scheme B Fold 3 ---\n",
            "-- Cycle 1 --\n",
            "-- Cycle 2 --\n",
            "-- Cycle 3 --\n",
            "-- Cycle 4 --\n",
            "-- Cycle 5 --\n",
            "-- Cycle 6 --\n",
            "-- Cycle 7 --\n",
            "-- Cycle 8 --\n",
            "-- Cycle 9 --\n",
            "-- Cycle 10 --\n",
            "Accuracy: 0.828, Precision: 0.854, Recall: 0.761, F1: 0.805\n",
            "\n",
            "--- SCANN Scheme B Cross-Validation Summary ---\n",
            "Accuracy : 0.825\n",
            "Precision: 0.838\n",
            "Recall   : 0.767\n",
            "F1 Score : 0.800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define TUTOR Functions\n",
        "def syn_data_gen_kde(X_train, X_val, num_samples=20000, cols=[0, 2, 5, 6, 8, 10, 12]):\n",
        "    bandwidths = [0.5, 0.7, 1.0, 1.5, 2.0, 3.0]\n",
        "    log_likelihoods = []\n",
        "\n",
        "    for bw in bandwidths:\n",
        "        kde = KernelDensity(kernel='gaussian', bandwidth=bw)\n",
        "        kde.fit(X_train)\n",
        "        log_likelihood = kde.score(X_val)\n",
        "        log_likelihoods.append(log_likelihood)\n",
        "\n",
        "    best_bw = bandwidths[np.argmax(log_likelihoods)]\n",
        "\n",
        "    kde_final = KernelDensity(kernel='gaussian', bandwidth=best_bw)\n",
        "    kde_final.fit(X_train)\n",
        "    X_syn = kde_final.sample(num_samples)\n",
        "\n",
        "    for i in range(X_syn.shape[0]):\n",
        "        cat_values = X_syn[i, list(cols)]\n",
        "        max_idx = np.argmax(cat_values)\n",
        "        for j, col in enumerate(cols):\n",
        "            X_syn[i, col] = 1 if j == max_idx else 0\n",
        "\n",
        "    return X_syn\n",
        "\n",
        "def semantic_integrity_classifier(X_syn, X_train, X_val, cont_cols, cat_range):\n",
        "    # Combine training + validation\n",
        "    X_total = np.vstack([X_train, X_val])\n",
        "    y_total = np.argmax(X_total[:, cat_range[0]:cat_range[1]], axis=1)\n",
        "\n",
        "    # Train classifier on continuous features to predict categorical class\n",
        "    clf = RandomForestClassifier(random_state=42)\n",
        "    clf.fit(X_total[:, cont_cols], y_total)\n",
        "\n",
        "    # Validate each synthetic row\n",
        "    valid_syn = []\n",
        "    for row in X_syn:\n",
        "        x_cont = row[cont_cols].reshape(1, -1)\n",
        "        pred_class = clf.predict(x_cont)[0]\n",
        "        actual_class = np.argmax(row[cat_range[0]:cat_range[1]])\n",
        "\n",
        "        # Check integrity\n",
        "        if pred_class == actual_class:\n",
        "            # Fix one-hot encoding explicitly\n",
        "            corrected_row = row.copy()\n",
        "            corrected_row[cat_range[0]:cat_range[1]] = 0\n",
        "            corrected_row[cat_range[0] + pred_class] = 1\n",
        "            valid_syn.append(corrected_row)\n",
        "\n",
        "    valid_syn = np.array(valid_syn)\n",
        "    print(f\"Kept {len(valid_syn)} / {len(X_syn)} synthetic samples after semantic filtering\")\n",
        "    return valid_syn\n",
        "\n",
        "def build_combined_model(input_dim, hidden_units):\n",
        "    # Create two sub-networks\n",
        "    model1 = build_model(input_dim, hidden_units)\n",
        "    model2 = build_model(input_dim, hidden_units)\n",
        "\n",
        "    # Use the models as inputs for the combined model\n",
        "    input1 = model1.input\n",
        "    input2 = model2.input\n",
        "    output1 = model1.output\n",
        "    output2 = model2.output\n",
        "\n",
        "    # Concatenate outputs from both models\n",
        "    combined_output = tf.keras.layers.concatenate([output1, output2])\n",
        "\n",
        "    # Define a new model\n",
        "    combined_model = tf.keras.Model(inputs=[input1, input2], outputs=combined_output)\n",
        "\n",
        "    return combined_model\n",
        "\n",
        "def find_best_rf_max_depth(X_train, y_train, X_val, y_val, max_depth_range=(1, 25)):\n",
        "    validation_accs = []\n",
        "    train_accs = []\n",
        "\n",
        "    for max_depth in range(*max_depth_range):\n",
        "        print(f\"Training Random forest max_depth={max_depth}\")\n",
        "        rf = RandomForestClassifier(n_estimators=350, max_depth=max_depth, criterion='gini', random_state=42)\n",
        "\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        # Train accuracy\n",
        "        y_pred_train = rf.predict(X_train)\n",
        "        train_acc = accuracy_score(y_train, y_pred_train)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # Validation accuracy\n",
        "        y_pred_val = rf.predict(X_val)\n",
        "        validation_acc = accuracy_score(y_val, y_pred_val)\n",
        "        validation_accs.append(validation_acc)\n",
        "\n",
        "    # Plot accuracy vs. max_depth\n",
        "    plt.title('Training and Validation Accuracy vs. Tree Depth')\n",
        "    plt.plot(range(*max_depth_range), train_accs, label='Training accuracy')\n",
        "    plt.plot(range(*max_depth_range), validation_accs, label='Validation accuracy')\n",
        "    plt.xlabel('Max Depth')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Best max_depth based on validation accuracy\n",
        "    best_tree_id = np.argmax(validation_accs)\n",
        "    best_max_depth = best_tree_id + 1  # Because the range starts from 1\n",
        "    print(f\"Best Random Forest max_depth={best_max_depth}\")\n",
        "    print(f\"train acc={train_accs[best_tree_id]}\")\n",
        "    print(f\"validation acc={validation_accs[best_tree_id]}\")\n",
        "\n",
        "    return best_max_depth, train_accs, validation_accs\n"
      ],
      "metadata": {
        "id": "QTGJ1gdFx5gm"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TUTOR Scheme A\n",
        "accs_a, precs_a, recs_a, f1s_a = [], [], [], []\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0)\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "Fcats = [0, 2, 5, 6, 8, 10, 12]  # categorical feature indices\n",
        "Fcont = [i for i in range(X_df.shape[1]) if i not in Fcats]  # continuous features\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X_df, y_df), 1):\n",
        "    print(f\"\\n--- TUTOR Scheme A Fold {fold} ---\")\n",
        "\n",
        "    X_trainval = X_df.iloc[train_idx]\n",
        "    y_trainval = y_df.iloc[train_idx]\n",
        "    X_test = X_df.iloc[test_idx]\n",
        "    y_test = y_df.iloc[test_idx]\n",
        "\n",
        "    # Split trainval into train and val\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval\n",
        "    )\n",
        "\n",
        "    X_tr_arr = X_train.values.astype(np.float32)\n",
        "    X_val_arr = X_val.values.astype(np.float32)\n",
        "    X_te_arr = X_test.values.astype(np.float32)\n",
        "\n",
        "    y_tr = y_train.values.ravel()\n",
        "    y_te = y_test.values.ravel()\n",
        "    y_va = y_val.values.ravel()\n",
        "\n",
        "    # 1) Preprocessing: scale + PCA on continuous features\n",
        "    scaler = StandardScaler().fit(X_tr_arr[:, Fcont])\n",
        "    X_tr_s = scaler.transform(X_tr_arr[:, Fcont])\n",
        "    X_te_s = scaler.transform(X_te_arr[:, Fcont])\n",
        "    X_val_s = scaler.transform(X_val_arr[:, Fcont])\n",
        "    pca = PCA(n_components=0.95, whiten=True).fit(X_tr_s)\n",
        "    X_tr_pca = pca.transform(X_tr_s)\n",
        "    X_te_pca = pca.transform(X_te_s)\n",
        "    X_val_pca = pca.transform(X_val_s)\n",
        "\n",
        "    # 2) Train labeler on real data\n",
        "    best_max_depth, train_accs, validation_accs = find_best_rf_max_depth(X_tr_pca, y_tr, X_val_pca, y_va)\n",
        "    rf_best = RandomForestClassifier(n_estimators=350, max_depth=best_max_depth, criterion='gini', random_state=42)\n",
        "    rf_best.fit(X_tr_pca, y_tr)\n",
        "\n",
        "    # 3) Generate synthetic data\n",
        "    X_syn_raw = syn_data_gen_kde(X_train, X_val)\n",
        "    X_syn_arr = X_syn_raw.astype(np.float32)\n",
        "\n",
        "    # 4) Filter synthetic data with semantic classifier\n",
        "    verified_syn = semantic_integrity_classifier(\n",
        "        X_syn_arr,\n",
        "        X_tr_arr,\n",
        "        X_val_arr,\n",
        "        Fcont,\n",
        "        Fcats\n",
        "    )\n",
        "\n",
        "    # 5) Label and preprocess filtered synthetics\n",
        "    X_syn_s = scaler.transform(verified_syn[:, Fcont])\n",
        "    X_syn_pca = pca.transform(X_syn_s)\n",
        "    y_syn = rf.predict(X_syn_pca)\n",
        "\n",
        "    # 6) Compute class weights\n",
        "    cw = class_weight.compute_class_weight('balanced', classes=np.unique(y_tr), y=y_tr)\n",
        "    cw_dict = dict(enumerate(cw))\n",
        "\n",
        "    # 7) Pretrain on synthetic data\n",
        "    model = build_model(input_dim=X_tr_pca.shape[1], hidden_units=200)\n",
        "    model.fit(X_syn_pca, y_syn, epochs=500, batch_size=32, verbose=0)\n",
        "\n",
        "    # 8) Fine-tune on real data\n",
        "    history = model.fit(\n",
        "        X_tr_pca, y_tr,\n",
        "        validation_split=0.1,\n",
        "        epochs=1500,\n",
        "        batch_size=32,\n",
        "        class_weight=cw_dict,\n",
        "        callbacks=[reduce_lr, es],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # 9) Evaluate on test set\n",
        "    y_pred = (model.predict(X_te_pca, batch_size=32, verbose=0) > 0.5).astype(int).ravel()\n",
        "    a = accuracy_score(y_te, y_pred)\n",
        "    p = precision_score(y_te, y_pred, zero_division=0)\n",
        "    r = recall_score(y_te, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_te, y_pred, zero_division=0)\n",
        "    print(f\"Accuracy: {a:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "    accs_a.append(a); precs_a.append(p); recs_a.append(r); f1s_a.append(f1)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n--- TUTOR Scheme A Cross-Validation Summary ---\")\n",
        "print(f\"Accuracy : {np.mean(accs_a):.3f}\")\n",
        "print(f\"Precision: {np.mean(precs_a):.3f}\")\n",
        "print(f\"Recall   : {np.mean(recs_a):.3f}\")\n",
        "print(f\"F1 Score : {np.mean(f1s_a):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EpSor2pIks5q",
        "outputId": "fe69d95c-6ee6-4d35-cde7-7b45088dd57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TUTOR Scheme A Fold 1 ---\n",
            "Training Random forest max_depth=1\n",
            "Training Random forest max_depth=2\n",
            "Training Random forest max_depth=3\n",
            "Training Random forest max_depth=4\n",
            "Training Random forest max_depth=5\n",
            "Training Random forest max_depth=6\n",
            "Training Random forest max_depth=7\n",
            "Training Random forest max_depth=8\n",
            "Training Random forest max_depth=9\n",
            "Training Random forest max_depth=10\n",
            "Training Random forest max_depth=11\n",
            "Training Random forest max_depth=12\n",
            "Training Random forest max_depth=13\n",
            "Training Random forest max_depth=14\n",
            "Training Random forest max_depth=15\n",
            "Training Random forest max_depth=16\n",
            "Training Random forest max_depth=17\n",
            "Training Random forest max_depth=18\n",
            "Training Random forest max_depth=19\n",
            "Training Random forest max_depth=20\n",
            "Training Random forest max_depth=21\n",
            "Training Random forest max_depth=22\n",
            "Training Random forest max_depth=23\n",
            "Training Random forest max_depth=24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest max_depth=4\n",
            "train acc=0.9113924050632911\n",
            "validation acc=0.775\n",
            "Kept 10904 / 20000 synthetic samples after semantic filtering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TUTOR Scheme B\n",
        "accs_b, precs_b, recs_b, f1s_b = [], [], [], []\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0)\n",
        "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "Fcats = [0, 2, 5, 6, 8, 10, 12]\n",
        "Fcont = [i for i in range(X_df.shape[1]) if i not in Fcats]\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(X_df, y_df), 1):\n",
        "    print(f\"\\n--- TUTOR Scheme B Fold {fold} ---\")\n",
        "\n",
        "    # Train/test split\n",
        "    X_trainval = X_df.iloc[train_idx]\n",
        "    y_trainval = y_df.iloc[train_idx]\n",
        "    X_test = X_df.iloc[test_idx]\n",
        "    y_test = y_df.iloc[test_idx]\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_trainval, y_trainval, test_size=0.2, stratify=y_trainval, random_state=42\n",
        "    )\n",
        "\n",
        "    X_tr_arr = X_train.values.astype(np.float32)\n",
        "    X_val_arr = X_val.values.astype(np.float32)\n",
        "    X_te_arr = X_test.values.astype(np.float32)\n",
        "\n",
        "    y_tr = y_train.values.ravel()\n",
        "    y_val = y_val.values.ravel()\n",
        "    y_te = y_test.values.ravel()\n",
        "\n",
        "    # Scale + PCA\n",
        "    scaler = StandardScaler().fit(X_tr_arr[:, Fcont])\n",
        "    X_tr_s = scaler.transform(X_tr_arr[:, Fcont])\n",
        "    X_val_s = scaler.transform(X_val_arr[:, Fcont])\n",
        "    X_te_s = scaler.transform(X_te_arr[:, Fcont])\n",
        "    pca = PCA(n_components=0.95, whiten=True).fit(X_tr_s)\n",
        "    X_tr_pca = pca.transform(X_tr_s)\n",
        "    X_val_pca = pca.transform(X_val_s)\n",
        "    X_te_pca = pca.transform(X_te_s)\n",
        "\n",
        "    # Random Forest KB\n",
        "    rf = RandomForestClassifier(n_estimators=350, random_state=42)\n",
        "    rf.fit(X_tr_pca, y_tr)\n",
        "\n",
        "    # Synthetic data\n",
        "    X_syn_raw = syn_data_gen_kde(X_train, X_val)\n",
        "    verified_syn = semantic_integrity_classifier(X_syn_raw, X_tr_arr, X_val_arr, Fcont, Fcats)\n",
        "    X_syn_s = scaler.transform(verified_syn[:, Fcont])\n",
        "    X_syn_pca = pca.transform(X_syn_s)\n",
        "    y_syn = rf.predict(X_syn_pca)\n",
        "\n",
        "    # Train individual models\n",
        "    model_syn = build_model(input_dim=X_tr_pca.shape[1], hidden_units=200)\n",
        "    model_syn.fit(X_syn_pca, y_syn, epochs=200, batch_size=32, verbose=0)\n",
        "\n",
        "    model_real = build_model(input_dim=X_tr_pca.shape[1], hidden_units=200)\n",
        "    model_real.fit(X_tr_pca, y_tr, epochs=200, batch_size=32, verbose=0)\n",
        "\n",
        "    # Get representations from each\n",
        "    model_syn(X_tr_pca[:1])\n",
        "    extractor_syn = Model(inputs=model_syn.input, outputs=model_syn.layers[-2].output)\n",
        "    extractor_real = Model(inputs=model_real.input, outputs=model_real.layers[-2].output)\n",
        "\n",
        "    X_tr_syn_out = extractor_syn.predict(X_tr_pca, verbose=0)\n",
        "    X_tr_real_out = extractor_real.predict(X_tr_pca, verbose=0)\n",
        "\n",
        "    X_val_syn_out = extractor_syn.predict(X_val_pca, verbose=0)\n",
        "    X_val_real_out = extractor_real.predict(X_val_pca, verbose=0)\n",
        "\n",
        "    X_te_syn_out = extractor_syn.predict(X_te_pca, verbose=0)\n",
        "    X_te_real_out = extractor_real.predict(X_te_pca, verbose=0)\n",
        "\n",
        "    # Build combined model\n",
        "    combined_model = build_combined_model(input_dim=X_tr_pca.shape[1], hidden_units=200)\n",
        "    history = combined_model.fit(\n",
        "        [X_tr_pca, X_tr_pca], y_tr,\n",
        "        validation_data=([X_val_pca, X_val_pca], y_val),\n",
        "        epochs=500,\n",
        "        batch_size=32,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    y_pred = (combined_model.predict([X_te_pca, X_te_pca], batch_size=32, verbose=0) > 0.5).astype(int).ravel()\n",
        "    a = accuracy_score(y_te, y_pred)\n",
        "    p = precision_score(y_te, y_pred, zero_division=0)\n",
        "    r = recall_score(y_te, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_te, y_pred, zero_division=0)\n",
        "    print(f\"Accuracy: {a:.3f}, Precision: {p:.3f}, Recall: {r:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "    accs_b.append(a); precs_b.append(p); recs_b.append(r); f1s_b.append(f1)\n",
        "\n",
        "# Summary\n",
        "print(\"\\n--- TUTOR Scheme B Cross-Validation Summary ---\")\n",
        "print(f\"Mean Accuracy: {np.mean(accs_b):.3f}\")\n",
        "print(f\"Mean Precision: {np.mean(precs_b):.3f}\")\n",
        "print(f\"Mean Recall: {np.mean(recs_b):.3f}\")\n",
        "print(f\"Mean F1 Score: {np.mean(f1s_b):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "yDnQV6hRFbVq",
        "outputId": "2d6fcf48-cd20-4231-e671-717855916033"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TUTOR Scheme B Fold 1 ---\n",
            "Kept 10741 / 20000 synthetic samples after semantic filtering\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable Functional object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-03f7eb11d8a1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Build combined model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mcombined_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_combined_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_tr_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     history = combined_model.fit(\n\u001b[1;32m     77\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mX_tr_pca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr_pca\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-52c42bbc8552>\u001b[0m in \u001b[0;36mbuild_combined_model\u001b[0;34m(input_dim, hidden_units)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_combined_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Create two sub-networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0minp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0minp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable Functional object"
          ]
        }
      ]
    }
  ]
}